{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d737a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones sell_in: (2945818, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33 entries, 20001 to 20838\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tn_0      33 non-null     float64\n",
      " 1   tn_mas_2  33 non-null     float64\n",
      " 2   tn_1      33 non-null     float64\n",
      " 3   tn_2      33 non-null     float64\n",
      " 4   tn_3      33 non-null     float64\n",
      " 5   tn_4      33 non-null     float64\n",
      " 6   tn_5      33 non-null     float64\n",
      " 7   tn_6      33 non-null     float64\n",
      " 8   tn_7      33 non-null     float64\n",
      " 9   tn_8      33 non-null     float64\n",
      " 10  tn_9      33 non-null     float64\n",
      " 11  tn_10     33 non-null     float64\n",
      " 12  tn_11     33 non-null     float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 3.6 KB\n",
      "Fitting 25 folds for each of 100 candidates, totalling 2500 fits\n",
      "alpha óptimo: 100.0\n",
      "Mejor alpha encontrado: 100.0\n",
      "MSE CV promedio (25 folds): 3125.2845\n",
      "    param_alpha  mean_test_score  std_test_score\n",
      "0     10.000000     -6317.870328    14666.405727\n",
      "1     10.235310     -6296.390977    14589.661071\n",
      "2     10.476158     -6274.516594    14512.047772\n",
      "3     10.722672     -6252.270187    14432.917541\n",
      "4     10.974988     -6229.563215    14352.178433\n",
      "..          ...              ...             ...\n",
      "95    91.116276     -3201.071306     4982.008831\n",
      "96    93.260335     -3182.336593     4952.702151\n",
      "97    95.454846     -3163.685763     4923.153649\n",
      "98    97.700996     -3143.677861     4892.403675\n",
      "99   100.000000     -3125.284484     4862.295199\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "\n",
      "Coeficientes ordenados (de mayor a menor):\n",
      "tn_1     0.228389\n",
      "tn_8     0.164710\n",
      "tn_6     0.133017\n",
      "tn_2     0.126566\n",
      "tn_10    0.116725\n",
      "tn_9     0.080961\n",
      "tn_11    0.070836\n",
      "tn_7     0.013293\n",
      "tn_0     0.000000\n",
      "tn_3    -0.000000\n",
      "tn_5     0.000000\n",
      "tn_4    -0.098202\n",
      "dtype: float64\n",
      "\n",
      "Intercepto: -0.3576667615471081\n",
      "\n",
      "MSE en training: 976.4091\n",
      "Predicciones guardadas en ../data/predicciones_lasso_v9.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0) SETUP: rutas e imports\n",
    "# ============================\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadir la raíz del proyecto (donde está tu carpeta src/)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "# 1) CARGA DE DATOS\n",
    "# ============================\n",
    "sell_in       = pd.read_csv('../data/sell-in.txt', sep='\\t')\n",
    "prod_vigentes = pd.read_csv('../data/product_id_apredecir201912.txt', sep='\\t')\n",
    "productos     = pd.read_csv('../data/tb_productos_05262025.txt', sep='\\t')\n",
    "\n",
    "# ============================\n",
    "# 2) PARSEO DE FECHAS\n",
    "# ============================\n",
    "sell_in['periodo'] = pd.to_datetime(\n",
    "    sell_in['periodo'].astype(str) + '01',\n",
    "    format='%Y%m%d'\n",
    ")\n",
    "print(\"Dimensiones sell_in:\", sell_in.shape)\n",
    "\n",
    "# ============================\n",
    "# 3) AGREGADOS INICIALES\n",
    "# ============================\n",
    "sell_in_agg = (\n",
    "    sell_in\n",
    "    .groupby(['periodo','product_id'], as_index=False)\n",
    "    .agg({'tn': 'sum'})\n",
    ")\n",
    "\n",
    "# Filtrar solo productos vigentes\n",
    "sell_in_agg = sell_in_agg.merge(\n",
    "    prod_vigentes[['product_id']],\n",
    "    on='product_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Campo objetivo a 2 periodos en el futuro\n",
    "sell_in_agg['tn_mas_2'] = sell_in_agg.groupby('product_id')['tn'].shift(-2)\n",
    "\n",
    "# Lags de tn, del mes anterior hasta 11 meses atrás\n",
    "for lag in range(1, 12):\n",
    "    sell_in_agg[f'tn_{lag}'] = (\n",
    "        sell_in_agg\n",
    "        .groupby('product_id')['tn']\n",
    "        .shift(lag)\n",
    "    )\n",
    "\n",
    "# Renombrar tn actual a tn_0\n",
    "sell_in_agg.rename(columns={'tn': 'tn_0'}, inplace=True)\n",
    "\n",
    "# ============================\n",
    "# 4) PREPARAR DATOS DE ENTRENAMIENTO (solo diciembre 2018)\n",
    "# ============================\n",
    "dataset_training = (\n",
    "    sell_in_agg[sell_in_agg['periodo'] == '2018-12-01']\n",
    "    .dropna(subset=['tn_mas_2'] + [f'tn_{i}' for i in range(12)])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "magicos = [\n",
    " 20002,20003,20006,20010,20011,20018,20019,20021,\n",
    " 20026,20028,20035,20039,20042,20044,20045,20046,\n",
    " 20049,20051,20052,20053,20055,20008,20001,20017,\n",
    " 20086,20180,20193,20320,20532,20612,20637,20807,20838\n",
    "]\n",
    "\n",
    "df_magicos = dataset_training[dataset_training['product_id'].isin(magicos)].copy()\n",
    "df_magicos.drop(columns=['periodo'], inplace=True)\n",
    "df_magicos.set_index('product_id', inplace=True)\n",
    "df_magicos.info()\n",
    "\n",
    "# ============================\n",
    "# 5) DEFINIR X e y\n",
    "# ============================\n",
    "feature_cols = [f'tn_{i}' for i in range(12)]\n",
    "X_train = df_magicos[feature_cols]\n",
    "y_train = df_magicos['tn_mas_2']\n",
    "\n",
    "# ============================\n",
    "# 6) ENTRENAR Lasso con GridSearchCV (cv=50)\n",
    "# ============================\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Malla de alphas\n",
    "#param_grid = {'alpha': np.logspace(1, 2, 100)}\n",
    "param_grid = {'alpha': [-1 , 1, 10, 50, 100, 200, 500, 1000, 2000, 5000]}\n",
    "\n",
    "# Modelo base\n",
    "lasso = Lasso(max_iter=5000, random_state=42)\n",
    "folds = 25\n",
    "# GridSearch con 33 folds y MSE negativo\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lasso,\n",
    "    param_grid=param_grid,\n",
    "    cv=folds,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajuste\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_alpha  = grid_search.best_params_['alpha']\n",
    "best_lasso  = grid_search.best_estimator_\n",
    "best_cv_mse = -grid_search.best_score_\n",
    "print(\"alpha óptimo:\", grid_search.best_params_['alpha'])\n",
    "\n",
    "print(f\"Mejor alpha encontrado: {best_alpha}\")\n",
    "print(f\"MSE CV promedio ({folds} folds): {best_cv_mse:.4f}\")\n",
    "\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(cv_results[['param_alpha', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# ============================\n",
    "# 7) MÉTRICAS y COEFICIENTES\n",
    "# ============================\n",
    "coef = pd.Series(best_lasso.coef_, index=feature_cols)\n",
    "print(\"\\nCoeficientes ordenados (de mayor a menor):\")\n",
    "print(coef.sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nIntercepto:\", best_lasso.intercept_)\n",
    "\n",
    "y_train_pred = best_lasso.predict(X_train)\n",
    "mse_train    = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"\\nMSE en training: {mse_train:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 8) PREPARAR DATOS PARA PREDICCIÓN (2019-12)\n",
    "# ============================\n",
    "dataset_201912 = (\n",
    "    sell_in_agg[sell_in_agg['periodo'] == '2019-12-01']\n",
    "    .merge(prod_vigentes[['product_id']], on='product_id', how='inner')\n",
    "    .drop(columns=['tn_mas_2','periodo'])\n",
    ")\n",
    "\n",
    "complete   = dataset_201912.dropna(subset=feature_cols)\n",
    "incomplete = dataset_201912[dataset_201912[feature_cols].isna().any(axis=1)].copy()\n",
    "incomplete[feature_cols] = incomplete[feature_cols].apply(\n",
    "    lambda row: row.fillna(row.mean()), axis=1\n",
    ")\n",
    "\n",
    "dataset_final = pd.concat([complete, incomplete], ignore_index=True)\n",
    "\n",
    "# ============================\n",
    "# 9) PREDICCIÓN y GUARDADO\n",
    "# ============================\n",
    "X_new = dataset_final[feature_cols]\n",
    "y_pred = best_lasso.predict(X_new)\n",
    "\n",
    "predicciones = pd.DataFrame({\n",
    "    'product_id': dataset_final['product_id'],\n",
    "    'tn_predicho': y_pred\n",
    "})\n",
    "\n",
    "predicciones.sort_values(by='product_id', inplace=True)\n",
    "predicciones.to_csv('../data/predicciones_lasso_v9.csv', index=False)\n",
    "print(\"Predicciones guardadas en ../data/predicciones_lasso_v9.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_env_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
