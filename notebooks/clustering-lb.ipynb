{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e3bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv('../data/ventas_featurev4.csv', sep=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9992ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar estadísticas históricas de tn\n",
    "lag_cols = [f'tn_lag_{i}' for i in range(1, 37)]\n",
    "df['tn_mean'] = df[lag_cols].mean(axis=1)\n",
    "df['tn_std'] = df[lag_cols].std(axis=1)\n",
    "df['tn_max'] = df[lag_cols].max(axis=1)\n",
    "df['tn_min'] = df[lag_cols].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277ea665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar variables categóricas relevantes\n",
    "le_cat1 = LabelEncoder()\n",
    "le_brand = LabelEncoder()\n",
    "df['cat1_enc'] = le_cat1.fit_transform(df['cat1'].astype(str))\n",
    "df['brand_enc'] = le_brand.fit_transform(df['brand'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c712f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas de lags y deltas\n",
    "columnas_cluster = [col for col in df.columns if col.startswith('tn_lag_') or col.startswith('delta_tn_lag_')]\n",
    "columnas_cluster += ['tn_mean', 'tn_std', 'tn_max', 'tn_min',\n",
    "                     'sku_size', 'productos_estrella', 'cliente_estrella',\n",
    "                     'cat1_enc', 'brand_enc']\n",
    "\n",
    "# Eliminar filas con nulos\n",
    "df_filtrado = df.dropna(subset=columnas_cluster)\n",
    "\n",
    "# Tomar una muestra para análisis (por rendimiento)\n",
    "df_sample = df_filtrado.sample(n=100_000, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052131b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_sample[columnas_cluster])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855aab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "k = 6\n",
    "mbk = MiniBatchKMeans(n_clusters=k, batch_size=10000, random_state=42)\n",
    "df_sample['cluster'] = mbk.fit_predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd54d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tn_lag_1  tn_lag_2  tn_lag_3  tn_lag_4  tn_lag_5  tn_lag_6  tn_lag_7  \\\n",
      "cluster                                                                         \n",
      "0        0.075793  0.089259  0.095387  0.094208  0.107327  0.119904  0.116771   \n",
      "1        1.696072  1.629516  1.398339  1.478072  1.383248  1.368870  0.889433   \n",
      "2        0.004472  0.004497  0.005070  0.004820  0.005393  0.006109  0.004857   \n",
      "3        0.012874  0.013639  0.012956  0.011654  0.012788  0.013977  0.014156   \n",
      "4        0.016531  0.016232  0.017577  0.017124  0.018280  0.019048  0.017225   \n",
      "5        0.014797  0.014453  0.015571  0.015859  0.015465  0.016104  0.017456   \n",
      "\n",
      "         tn_lag_8  tn_lag_9  tn_lag_10  ...  delta_tn_lag_35   tn_mean  \\\n",
      "cluster                                 ...                              \n",
      "0        0.117737  0.123790   0.133275  ...        -0.178423  0.158026   \n",
      "1        1.115618  0.846360   0.623461  ...         2.424598  0.548946   \n",
      "2        0.006366  0.005624   0.006255  ...        -0.004422  0.006960   \n",
      "3        0.014577  0.014524   0.014366  ...        -0.010230  0.016428   \n",
      "4        0.017251  0.019026   0.018942  ...        -0.015882  0.020118   \n",
      "5        0.018166  0.019272   0.017285  ...        -0.017409  0.021695   \n",
      "\n",
      "           tn_std    tn_max  tn_min    sku_size  productos_estrella  \\\n",
      "cluster                                                               \n",
      "0        0.309570  1.443907     0.0  700.418058            0.053048   \n",
      "1        1.443476  7.115941     0.0  549.053393            0.061179   \n",
      "2        0.017200  0.086567     0.0  219.019911            0.000000   \n",
      "3        0.041190  0.199426     0.0  686.875512            0.000000   \n",
      "4        0.045446  0.218386     0.0  438.064904            0.000000   \n",
      "5        0.049946  0.238759     0.0  159.317111            0.012037   \n",
      "\n",
      "         cliente_estrella  cat1_enc  brand_enc  \n",
      "cluster                                         \n",
      "0                0.017727  1.632803   6.969781  \n",
      "1                0.746941  0.951057  17.774194  \n",
      "2                0.000000  2.000000  20.903257  \n",
      "3                0.000000  1.000958  20.185818  \n",
      "4                0.026774  1.976683  29.926919  \n",
      "5                0.000000  0.000000  17.470253  \n",
      "\n",
      "[6 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ver resumen\n",
    "resumen_clusters = df_sample.groupby('cluster')[columnas_cluster].mean()\n",
    "print(resumen_clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3746e2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_cluster.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar modelo para aplicar luego\n",
    "import joblib\n",
    "joblib.dump(mbk, 'modelo_cluster.joblib')\n",
    "joblib.dump(scaler, 'scaler_cluster.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd24064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_predicho\n",
      "0    5057408\n",
      "4    3554049\n",
      "2    2961130\n",
      "5    2917318\n",
      "3    1934861\n",
      "1     310914\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/cf9y1r_d6kn9wqbdpzbhks000000gn/T/ipykernel_53757/3289579027.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['cluster_predicho'] = mbk.predict(X_all)\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo y scaler\n",
    "mbk = joblib.load('modelo_cluster.joblib')\n",
    "scaler = joblib.load('scaler_cluster.joblib')\n",
    "\n",
    "# Escalar todo el dataset\n",
    "X_all = scaler.transform(df_filtrado[columnas_cluster])\n",
    "\n",
    "# Predecir\n",
    "df_filtrado['cluster_predicho'] = mbk.predict(X_all)\n",
    "\n",
    "# Ver distribución\n",
    "print(df_filtrado['cluster_predicho'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc1ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.to_csv('../data/ventas_featurev4_cluster.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
